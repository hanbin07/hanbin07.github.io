<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Portfolio</title>
    <link rel ="stylesheet" href="css/bootstrap.css">
    <script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
    <script type="text/javascript">
        $(document).ready( function() {
            $("#sidebar-wrapper").load("SideBar.html");  // 원하는 파일 경로를 삽입하면 된다
            $("#footers").load("footer.html");  // 추가 인클루드를 원할 경우 이런식으로 추가하면 된다
        });
    </script>
</head>

<body>
<div id="page-wrapper">
    <!-- 사이드바 -->
    <div id="sidebar-wrapper"></div>

    <!-- 본문 -->
    <div id="page-content-wrapper">
        <div class="container-fluid">
            <h1>Portfolio</h1>
            <br> <br>
            <h3>AudienceMR </h3>
            <br>
            <img style="width: 25cm; color: #484d50 ;padding-left:10px; padding-right:10px; margin-left: 10px; float: left;" src="Portfolio-images/1_Audience.PNG">
            <br>
            <div style=" width: 25cm;padding-left:10px; padding-right:10px; margin-left: 10px; font-size: 18px; color: #484d50 ;">
                <br>
                AudienceMR is designed as a multi-user mixed reality space that seamlessly extends the local user space to become a large, shared classroom where some of the audience members are seen seated in a real space, and more members are seen through an extended portal. AudienceMR can provide a sense of the presence of a large-scale crowd/audience with the associated spatial context. In contrast to virtual reality (VR), however, with mixed reality (MR), a lecturer can deliver content or conduct a performance from a real, actual, comfortable, and familiar local space, while interacting directly with real nearby objects, such as a desk, podium, educational props, instruments, and office materials. Such a design will elicit a realistic user experience closer to an actual classroom, which is currently prohibitive owing to the COVID-19 pandemic. 
                <br> <br>
                [Publication]: <i>Applied Science</i> <a href="https://www.mdpi.com/2076-3417/11/19/9022">Paper link</a><br> <br>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/idSctVJI4vo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

            </div>

            <hr width=”40cm” color= #6c757d noshade />
            <br>

            <h3>Interior application using augmented reality</h3>
            <br>
            <img style="width: 25cm; padding :10px; margin-left: 10px; float: left;;" src="Portfolio-images/2_Interior.PNG">
            <br>
            <div style=" width: 25cm; padding:10px; margin-left: 10px; margin-top: 15px;color: #484d50 ;font-size: 18px">
                Using an approximate 2D map of the environment generated from the latest environment modeling technology and enhance the object manipulation performance
                for the touch based mobile augmented reality. 
                <img style="width: 25cm; padding-right:10px; padding-bottom:5px; margin-right: 10px; float: left;" src="Portfolio-images/2_1_process.PNG"> <br>
                <br>
                [Publication]: <i>25th ACM Symposium on Virtual Reality Software and Technology</i> Poster <a href="https://dl.acm.org/doi/10.1145/3359996.3364715">Poster link</a><br> <br>
                <video style width="560" height="315" src = "Portfolio-images/2d-3d.mp4" autoplay controls muted></video>
            </div>

            <hr width=”40cm” color= #6c757d noshade />
            <br>

            <h3>Reverse Optical Flow Visualization Algorithm</h3>
            <br>
            <img style="width: 25cm; padding:10px; margin-left: 10px; margin-bottom: 10px; padding-bottom: 10px;float: left;"src="Portfolio-images/3_Reverse.PNG">
            <br> <br>

            <div style=" width: 25cm; padding:10px; margin-left: 10px; margin-top: 15px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                Simulation sickness has been one of the major obstacles toward making virtual reality (VR) widely accepted and used. For example,
                virtual navigation produces vection, which is the illusion of self-motion as one perceives bodily motion despite no movement actually
                occurring. This, in turn, causes a sensory conflict between visual and actual (or vestibular) motion and sickness. In this study, we explore
                a method to reduce VR sickness by visually mixing the optical flow patterns that are in the reverse direction of the virtual visual
                motion. As visual motion is mainly detected and perceived by the optical flow, artificial mixing in the reverse flow is hypothesized
                to induce a cancellation effect, thereby reducing the degree of conflict with the vestibular sense and sickness. <br>

                <img style="width: 25cm; margin-top: 5px; padding :10px; margin-right: 10px; float: left;" src="Portfolio-images/3_1_Architecture.PNG">

                <br>
                <i>The ACM Conference on Human Factors in Computing Systems (CHI) 2022.</i> [Accepted]
                <video style width="560" height="315" src = "Portfolio-images/3R.mp4" autoplay controls muted></video>

            </div>
            <hr width=”40cm” color= #6c757d noshade />

            <br>

            <h3>Lip animation generation for Hearing impairment and deafness</h3>
            <br>
            <img style="width: 25cm; padding:10px;  margin-left: 10px; float: left;" src="Portfolio-images/4_System.PNG">
            <br>
            <div style=" width: 25cm; padding:10px;  margin-left: 10px; margin-top: 15px; padding-top :20px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                Since COVID-19, it has become inevitable to wear masks in all places. Wearing a mask causes communication problems because people cannot see the lower part of the face. This project makes it possible to communicate efficiently by synthesizing animation at the bottom of the face in real-time.
                <br>
            </div>
            <hr width=”40cm” color= #6c757d noshade />

            <br>
            <h3>VR controller for Musical Instruments</h3>
            <br>
            <img style="width: 25cm; padding:10px;  margin-left: 10px; float: left;" src="Portfolio-images/5_1_user.PNG">
            <br>
            <div style=" width: 25cm; padding:10px;  margin-left: 10px; padding-top: 20px; margin-top: 20px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                Hand position and finger pose were measured using a Flex sensor and IMU. Users can play in a Virtual Environment without an actual instrument. Users can play musical instruments such as piano and guitar.
                The controller consists of 5 flex sensors for sensing finger pose. Using 9-axis IMU for sensing hand rotation, and a microcontroller (MBN52832) for processing sensor data. We used mux to collect data from the five flex sensors, and the IMU data is transmitted through the I2C protocol.

                <br>
               
                <br>
            </div>
            <hr width=”40cm” color= #6c757d noshade />

            <br>
            <h3>Low cost VR controller</h3>
            <br>
            <img style="width: 25cm; padding:10px; margin-left: 10px; float: left;" src="Portfolio-images/6_1_game.PNG">
            <img style="width: 25cm; padding:10px; margin-left: 10px; float: left;" src="Portfolio-images/6_2_3cont.PNG">
            <br>
            <div style=" width: 25cm;padding:10px; margin-left: 10px; padding-top: 20px;  margin-top: 20px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                Make VR controllers in an inexpensive and accessible way using cardboard boxes. It can be used for shooting games, racing games, and simulation games. It is a non-electricity controller.
                
                <br>
            </div>
            <hr width=”40cm” color= #6c757d noshade />
            <br>
            <h3>Virtual Reality Library</h3>
    
            <br>
            <img style="width: 25cm; padding:10px;  margin-left: 10px; float: left;" src="Portfolio-images/7_1.PNG">
            <br>
            <div style=" width: 25cm;padding:10px; margin-left: 10px; padding-top: 20px; margin-top: 20px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                We developed a system that a mobile VR app and links it with an offline library. Non-contact library technology allows people to look around offline libraries and rent books. I implemented a virtual reality library based on the information of books held in offline libraries.
                <br>
            </div>
            <br>
            <hr width=”40cm” color= #6c757d noshade />

            <h3>Architect</h3>
            <br>
            <img style="width: 25cm; padding:10px; margin-left: 10px; float: left;" src="Portfolio-images/8_1.PNG">
            <br>
            <div style=" width: 25cm;padding-left:10px; padding-right:10px; margin-left: 10px;padding-top: 20px; margin-top: 20px;color: #484d50 ;font-size: 18px" id ="MYprofile">
                I modeled the building and interior using the SketchUp and 3D CAD.
                <br>
            </div>

            <br>
            
            

        </div>
    </div>
    <!-- /본문 -->
    <div id="footers"></div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="js/bootstrap.js"></script>
</body>

</html>
